{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer import *\n",
    "import notebook_utils as nutils\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# import sys;\n",
    "# sys.path.append('/home/haotruong/Receipt/EasyOCR')\n",
    "\n",
    "# import easyocr\n",
    "# reader = easyocr.Reader(['en'], gpu=True)\n",
    "\n",
    "def recognize_text(img, bboxes, target=None):\n",
    "    offset = 5\n",
    "\n",
    "    total_result = []\n",
    "    \n",
    "    for bbox in np.array(bboxes, dtype=np.int32)[:]:\n",
    "        x0, y0, x1, y1 = bbox\n",
    "        i = img[y0 - offset: y1+offset, x0-offset : x1+offset]\n",
    "\n",
    "        results = []\n",
    "\n",
    "        for n in range(4):\n",
    "            data = reader.recognize(np.rot90(i, n))\n",
    "            text = data[0][1]\n",
    "            if target:\n",
    "                if (target in text) or (text in target):\n",
    "                    results.append(text)\n",
    "            else:\n",
    "                results.append(data[0][1])\n",
    "            \n",
    "        total_result.append(results)\n",
    "\n",
    "    return total_result\n",
    "\n",
    "classes = ['ocr']\n",
    "classes = ['552F', '550SF','550PF', '552SF', '551F', '551GPF', '522F']\n",
    "predictor = get_predictor(\"ocr_spec.pth\", classes, 800)\n",
    "file = 'OCR/552F/11.JPG'\n",
    "bboxes, classes, scores, v = infer('ocr', predictor, file, True, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_classes = ['552F', '550SF','550PF', '552SF', '551F', '551GPF', '522F']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = nutils.list_files(\"OCR\", \"**/*.JPG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp4_files = [Path(\"ocr_video.mp4\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([])\n",
    "len(np.where(a > 0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in mp4_files:\n",
    "    out = cv2.VideoWriter(\"temp.mp4\",cv2.VideoWriter_fourcc(*'MP4V'), 10, (640, 360)) #(640, 360) (285, 360)\n",
    "    \n",
    "    vc = cv2.VideoCapture(str(path))\n",
    "    time_per_frame = (1/vc.get(cv2.CAP_PROP_FPS)) * 1000\n",
    "\n",
    "#     vc.set(1, 2400);\n",
    "\n",
    "    rval = True\n",
    "\n",
    "    frame_id = 0\n",
    "    max_frame = int(vc.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "#     max_frame=200\n",
    "    \n",
    "    counter = 0\n",
    "\n",
    "    circle_coord = [200, 200]\n",
    "    pbar = tqdm(total=max_frame, position=0, leave=True)\n",
    "    while rval:\n",
    "        rval , frame = vc.read()\n",
    "\n",
    "        if rval:\n",
    "            start = time.time()\n",
    "\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            bboxes, classes, scores, v = infer('baocam', predictor, image, True, 0.5)\n",
    "            \n",
    "            if len(classes) > 0:\n",
    "                catch_len = len(np.where(classes > 0)[0])\n",
    "                if catch_len > 0:\n",
    "                    ###False\n",
    "                    v.draw_circle(circle_coord, 'b', radius=50)\n",
    "                else:\n",
    "                    v.draw_circle(circle_coord, 'g', radius=50)\n",
    "            else:\n",
    "                v.draw_circle(circle_coord, 'y', radius=50)\n",
    "\n",
    "\n",
    "            \n",
    "            total_time = (time.time() - start) * 1000\n",
    "\n",
    "            for bbox, class_id in zip(bboxes, classes):\n",
    "                v.draw_box(bbox, alpha = 1)\n",
    "                v.draw_text(base_classes[class_id], (int((bbox[0] + bbox[2])/2) , int((bbox[1])) - 20), font_size= 20, color='b')\n",
    "\n",
    "            predicted_image = v.output.get_image()\n",
    "\n",
    "            skip_frame = int(np.ceil(total_time / time_per_frame))\n",
    "            skip_frame = 3\n",
    "#             print(skip_frame)\n",
    "            out.write(predicted_image)\n",
    "\n",
    "            frame_id += 1\n",
    "            pbar.update(1)\n",
    "            \n",
    "            for i in range(skip_frame):\n",
    "                out.write(predicted_image)\n",
    "                vc.read()\n",
    "                pbar.update(1)\n",
    "                frame_id += 1\n",
    "\n",
    "            if frame_id > (max_frame - 0):\n",
    "                break\n",
    "\n",
    "    out.release()\n",
    "    vc.release()\n",
    "\n",
    "    new_file = \"{}_export.mp4\".format(path.stem).replace(\" \", \"\") \n",
    "    cmd = \"ffmpeg -i temp.mp4 -vcodec libx264 {} -y\".format(new_file)\n",
    "    print(cmd)\n",
    "    os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "Video(\"ocr_video_export.mp4\", width = 800)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, file in enumerate(files):    \n",
    "    try:\n",
    "        bboxes, classes, scores, v = infer('ocr', predictor, str(file), True, 0.5, True)\n",
    "\n",
    "        target = parse_file(str(file.with_suffix(\".xml\")))['object'][0]['name']\n",
    "\n",
    "    #         text_list = recognize_text(v.img, bboxes, target=target)\n",
    "\n",
    "        for classid, bbox in zip(classes, bboxes):\n",
    "            text = base_classes[classid]\n",
    "            v.draw_text(text, (int((bbox[0] + bbox[2])/2) , int((bbox[1])) - 20), font_size= 20, color='r')\n",
    "\n",
    "        cv2.imwrite(\"OCR/OCR_Result_2/{}.jpg\".format(index), cv2.cvtColor(v.output.get_image(), cv2.COLOR_RGB2BGR )   )\n",
    "\n",
    "        print(\"{} / {}\".format(index+1, len(files)))\n",
    "    except:\n",
    "        pass\n",
    "#     nutils.imshow(v.output.get_image(), 55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = nutils.list_files(\"OCR/OCR\", \"*.JPG\")\n",
    "for i, f in enumerate(files):\n",
    "    bboxes, classes, scores, v = infer('ocr', predictor, str(f), True, 0.5)\n",
    "    for bbox in bboxes:\n",
    "        v.draw_box(bbox, alpha = 1)\n",
    "\n",
    "    predicted_image = v.output.get_image()\n",
    "    \n",
    "    cv2.imwrite(\"OCR/OCR_Result/{}.jpg\".format(i), cv2.cvtColor(predicted_image, cv2.COLOR_RGB2BGR) )\n",
    "#     nutils.imshow(predicted_image)\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import notebook_utils as nutils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutils.imshow(cv2.imread(\"OCR/OCR_Result_2/{}.jpg\".format(300)), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp4_files = nutils.list_files(\"data\", \"CAM 1-*.mp4\")\n",
    "path = mp4_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_per_frame = (1/30) * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for path in mp4_files:\n",
    "    out = cv2.VideoWriter(\"temp.mp4\",cv2.VideoWriter_fourcc(*'MP4V'), 30, (640, 360))\n",
    "    vc = cv2.VideoCapture(str(path))\n",
    "\n",
    "#     start_frame = 10800#12600 #10800\n",
    "#     vc.set(1,start_frame);\n",
    "\n",
    "    rval = True\n",
    "\n",
    "    frame_id = 0\n",
    "    max_frame = int(vc.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    counter = 0\n",
    "\n",
    "    pbar = tqdm(total=max_frame, position=0, leave=True)\n",
    "    \n",
    "    mot_tracker = Sort(min_hits= 0)\n",
    "    mot_tracker.reset_count()\n",
    "    while rval:\n",
    "        rval , frame = vc.read()\n",
    "\n",
    "        if rval:\n",
    "            start = time.time()\n",
    "\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            bboxes, classes, scores, v = infer('baocam', predictor, image, True, 0.5)\n",
    "            track_bbs_ids = mot_tracker.update(bboxes)\n",
    "\n",
    "            for bbox in bboxes:\n",
    "                v.draw_box(bbox, alpha = 1)\n",
    "\n",
    "            for bbox in track_bbs_ids:\n",
    "                counter = bbox[-1]\n",
    "                v.draw_text(str(int(counter)), (int( (bbox[0] + bbox[2]) /2 ) , int((bbox[1] + bbox[3]) /2 )), font_size= 70, color='g')\n",
    "\n",
    "\n",
    "            v.draw_text(str(int(counter)), (200 , 200), font_size= 200, color='g')\n",
    "\n",
    "            predicted_image = v.output.get_image()\n",
    "            total_time = (time.time() - start) * 1000\n",
    "\n",
    "            skip_frame = int(np.ceil(total_time / time_per_frame))\n",
    "\n",
    "            out.write(predicted_image)\n",
    "\n",
    "            frame_id += 1\n",
    "            pbar.update(1)\n",
    "            \n",
    "            for i in range(skip_frame):\n",
    "                out.write(predicted_image)\n",
    "                vc.read()\n",
    "                pbar.update(1)\n",
    "                frame_id += 1\n",
    "\n",
    "\n",
    "    #         plt.imshow(predicted_image)\n",
    "    #         plt.show()\n",
    "\n",
    "#             print(frame_id)\n",
    "            if frame_id > (max_frame - 100):\n",
    "                break\n",
    "\n",
    "    out.release()\n",
    "    vc.release()\n",
    "\n",
    "    new_file = \"{}_export.mp4\".format(path.stem).replace(\" \", \"\") \n",
    "    cmd = \"ffmpeg -i temp.mp4 -vcodec libx264 {} -y\".format(new_file)\n",
    "    print(cmd)\n",
    "    os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "Video(new_file, width = 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.release()\n",
    "vc.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.draw_box(bboxes[0])\n",
    "\n",
    "out = v.output.get_image()\n",
    "\n",
    "nutils.imshow(out, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = cv2.VideoCapture(str(path))\n",
    "\n",
    "start_frame = 12640\n",
    "vc.set(1,start_frame);\n",
    "\n",
    "mot_tracker = Sort(min_hits= 0) \n",
    "mot_tracker.reset_count()\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rval , frame = vc.read()\n",
    "start = time.time()\n",
    "\n",
    "image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "bboxes, classes, scores, v = infer('baocam', predictor, image, True, 0.5)\n",
    "\n",
    "track_bbs_ids = mot_tracker.update(bboxes)\n",
    "\n",
    "\n",
    "for bbox in bboxes:\n",
    "    v.draw_box(bbox, 1)\n",
    "    \n",
    "for bbox in track_bbs_ids:\n",
    "    counter = bbox[-1]    \n",
    "    v.draw_box(bbox[:4], edge_color='r')\n",
    "\n",
    "        \n",
    "v.draw_text(str(int(counter)), (200 , 200), font_size= 200, color='g')\n",
    "\n",
    "predicted_image = v.output.get_image()\n",
    "\n",
    "total_time = (time.time() - start) * 1000\n",
    "\n",
    "skip_frame = int(np.ceil(total_time / time_per_frame))\n",
    "for i in range(skip_frame):\n",
    "    vc.read()\n",
    "    \n",
    "nutils.imshow(predicted_image, 15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
