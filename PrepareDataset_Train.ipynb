{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import notebook_utils as nutils\n",
    "nutils.gdrive_down('1IhktjApSsNS8aFhoVXbH7PEY07Ri_qJ8', 'image1.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import notebook_utils as nutils\n",
    "from train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['BAO CAM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_paths = nutils.list_files(\"BAOCAM\", \"**/*.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = output_set(xml_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: Train = 1190 - Val = 0 - Test = 210\n",
      "(640, 672, 704, 736, 768, 800)\n",
      "\u001b[32m[09/04 02:42:55 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[09/04 02:42:55 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 1190 images left.\n",
      "\u001b[32m[09/04 02:42:55 d2.data.common]: \u001b[0mSerializing 1190 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/04 02:42:55 d2.data.common]: \u001b[0mSerialized dataset takes 0.27 MiB\n",
      "\u001b[32m[09/04 02:42:55 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[09/04 02:42:55 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/04 02:42:55 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[09/04 02:43:06 d2.utils.events]: \u001b[0m eta: 0:27:58  iter: 19  total_loss: 1.252  loss_cls: 0.647  loss_box_reg: 0.581  loss_rpn_cls: 0.019  loss_rpn_loc: 0.008  time: 0.5554  data_time: 0.0182  lr: 0.000005  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:43:17 d2.utils.events]: \u001b[0m eta: 0:27:57  iter: 39  total_loss: 1.214  loss_cls: 0.608  loss_box_reg: 0.575  loss_rpn_cls: 0.013  loss_rpn_loc: 0.008  time: 0.5574  data_time: 0.0079  lr: 0.000010  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:43:29 d2.utils.events]: \u001b[0m eta: 0:27:48  iter: 59  total_loss: 1.135  loss_cls: 0.532  loss_box_reg: 0.572  loss_rpn_cls: 0.018  loss_rpn_loc: 0.009  time: 0.5595  data_time: 0.0079  lr: 0.000015  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:43:40 d2.utils.events]: \u001b[0m eta: 0:27:38  iter: 79  total_loss: 1.049  loss_cls: 0.461  loss_box_reg: 0.560  loss_rpn_cls: 0.013  loss_rpn_loc: 0.008  time: 0.5617  data_time: 0.0076  lr: 0.000020  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:43:51 d2.utils.events]: \u001b[0m eta: 0:27:27  iter: 99  total_loss: 1.011  loss_cls: 0.415  loss_box_reg: 0.563  loss_rpn_cls: 0.011  loss_rpn_loc: 0.008  time: 0.5620  data_time: 0.0077  lr: 0.000025  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:44:02 d2.utils.events]: \u001b[0m eta: 0:27:16  iter: 119  total_loss: 0.962  loss_cls: 0.358  loss_box_reg: 0.589  loss_rpn_cls: 0.011  loss_rpn_loc: 0.008  time: 0.5613  data_time: 0.0078  lr: 0.000030  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:44:14 d2.utils.events]: \u001b[0m eta: 0:27:04  iter: 139  total_loss: 0.944  loss_cls: 0.319  loss_box_reg: 0.586  loss_rpn_cls: 0.010  loss_rpn_loc: 0.007  time: 0.5605  data_time: 0.0085  lr: 0.000035  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:44:25 d2.utils.events]: \u001b[0m eta: 0:26:53  iter: 159  total_loss: 0.949  loss_cls: 0.287  loss_box_reg: 0.653  loss_rpn_cls: 0.009  loss_rpn_loc: 0.007  time: 0.5605  data_time: 0.0088  lr: 0.000040  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:44:36 d2.utils.events]: \u001b[0m eta: 0:26:42  iter: 179  total_loss: 0.904  loss_cls: 0.256  loss_box_reg: 0.625  loss_rpn_cls: 0.011  loss_rpn_loc: 0.005  time: 0.5608  data_time: 0.0079  lr: 0.000045  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:44:47 d2.utils.events]: \u001b[0m eta: 0:26:30  iter: 199  total_loss: 0.850  loss_cls: 0.220  loss_box_reg: 0.623  loss_rpn_cls: 0.007  loss_rpn_loc: 0.004  time: 0.5604  data_time: 0.0080  lr: 0.000050  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:44:58 d2.utils.events]: \u001b[0m eta: 0:26:19  iter: 219  total_loss: 0.826  loss_cls: 0.184  loss_box_reg: 0.622  loss_rpn_cls: 0.007  loss_rpn_loc: 0.004  time: 0.5605  data_time: 0.0077  lr: 0.000055  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:45:10 d2.utils.events]: \u001b[0m eta: 0:26:08  iter: 239  total_loss: 0.779  loss_cls: 0.163  loss_box_reg: 0.602  loss_rpn_cls: 0.005  loss_rpn_loc: 0.003  time: 0.5608  data_time: 0.0079  lr: 0.000060  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:45:21 d2.utils.events]: \u001b[0m eta: 0:25:57  iter: 259  total_loss: 0.726  loss_cls: 0.139  loss_box_reg: 0.575  loss_rpn_cls: 0.004  loss_rpn_loc: 0.003  time: 0.5608  data_time: 0.0080  lr: 0.000065  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:45:32 d2.utils.events]: \u001b[0m eta: 0:25:45  iter: 279  total_loss: 0.677  loss_cls: 0.114  loss_box_reg: 0.563  loss_rpn_cls: 0.004  loss_rpn_loc: 0.002  time: 0.5603  data_time: 0.0083  lr: 0.000070  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:45:43 d2.utils.events]: \u001b[0m eta: 0:25:34  iter: 299  total_loss: 0.630  loss_cls: 0.104  loss_box_reg: 0.524  loss_rpn_cls: 0.002  loss_rpn_loc: 0.003  time: 0.5605  data_time: 0.0083  lr: 0.000075  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:45:55 d2.utils.events]: \u001b[0m eta: 0:25:23  iter: 319  total_loss: 0.501  loss_cls: 0.078  loss_box_reg: 0.417  loss_rpn_cls: 0.001  loss_rpn_loc: 0.003  time: 0.5609  data_time: 0.0076  lr: 0.000080  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:46:06 d2.utils.events]: \u001b[0m eta: 0:25:12  iter: 339  total_loss: 0.343  loss_cls: 0.059  loss_box_reg: 0.283  loss_rpn_cls: 0.001  loss_rpn_loc: 0.004  time: 0.5612  data_time: 0.0075  lr: 0.000085  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:46:17 d2.utils.events]: \u001b[0m eta: 0:25:00  iter: 359  total_loss: 0.275  loss_cls: 0.058  loss_box_reg: 0.209  loss_rpn_cls: 0.001  loss_rpn_loc: 0.005  time: 0.5615  data_time: 0.0074  lr: 0.000090  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:46:29 d2.utils.events]: \u001b[0m eta: 0:24:49  iter: 379  total_loss: 0.222  loss_cls: 0.043  loss_box_reg: 0.176  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 0.5612  data_time: 0.0071  lr: 0.000095  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:46:40 d2.utils.events]: \u001b[0m eta: 0:24:38  iter: 399  total_loss: 0.200  loss_cls: 0.039  loss_box_reg: 0.145  loss_rpn_cls: 0.000  loss_rpn_loc: 0.004  time: 0.5611  data_time: 0.0080  lr: 0.000100  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:46:51 d2.utils.events]: \u001b[0m eta: 0:24:26  iter: 419  total_loss: 0.173  loss_cls: 0.041  loss_box_reg: 0.128  loss_rpn_cls: 0.000  loss_rpn_loc: 0.005  time: 0.5606  data_time: 0.0081  lr: 0.000105  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:47:02 d2.utils.events]: \u001b[0m eta: 0:24:15  iter: 439  total_loss: 0.182  loss_cls: 0.040  loss_box_reg: 0.136  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 0.5606  data_time: 0.0084  lr: 0.000110  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:47:13 d2.utils.events]: \u001b[0m eta: 0:24:04  iter: 459  total_loss: 0.153  loss_cls: 0.038  loss_box_reg: 0.110  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 0.5605  data_time: 0.0076  lr: 0.000115  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:47:24 d2.utils.events]: \u001b[0m eta: 0:23:52  iter: 479  total_loss: 0.151  loss_cls: 0.037  loss_box_reg: 0.112  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 0.5602  data_time: 0.0080  lr: 0.000120  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:47:36 d2.utils.events]: \u001b[0m eta: 0:23:41  iter: 499  total_loss: 0.140  loss_cls: 0.031  loss_box_reg: 0.099  loss_rpn_cls: 0.000  loss_rpn_loc: 0.003  time: 0.5603  data_time: 0.0075  lr: 0.000125  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:47:47 d2.utils.events]: \u001b[0m eta: 0:23:30  iter: 519  total_loss: 0.136  loss_cls: 0.034  loss_box_reg: 0.095  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 0.5604  data_time: 0.0073  lr: 0.000130  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:47:58 d2.utils.events]: \u001b[0m eta: 0:23:18  iter: 539  total_loss: 0.131  loss_cls: 0.032  loss_box_reg: 0.100  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 0.5602  data_time: 0.0080  lr: 0.000135  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:48:09 d2.utils.events]: \u001b[0m eta: 0:23:07  iter: 559  total_loss: 0.121  loss_cls: 0.029  loss_box_reg: 0.088  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5598  data_time: 0.0077  lr: 0.000140  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:48:20 d2.utils.events]: \u001b[0m eta: 0:22:56  iter: 579  total_loss: 0.122  loss_cls: 0.029  loss_box_reg: 0.088  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 0.5598  data_time: 0.0081  lr: 0.000145  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:48:31 d2.utils.events]: \u001b[0m eta: 0:22:44  iter: 599  total_loss: 0.114  loss_cls: 0.029  loss_box_reg: 0.083  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 0.5598  data_time: 0.0081  lr: 0.000150  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:48:42 d2.utils.events]: \u001b[0m eta: 0:22:33  iter: 619  total_loss: 0.124  loss_cls: 0.029  loss_box_reg: 0.098  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5595  data_time: 0.0078  lr: 0.000155  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:48:54 d2.utils.events]: \u001b[0m eta: 0:22:22  iter: 639  total_loss: 0.113  loss_cls: 0.025  loss_box_reg: 0.085  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 0.5596  data_time: 0.0079  lr: 0.000160  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:49:05 d2.utils.events]: \u001b[0m eta: 0:22:10  iter: 659  total_loss: 0.117  loss_cls: 0.028  loss_box_reg: 0.086  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5597  data_time: 0.0076  lr: 0.000165  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:49:16 d2.utils.events]: \u001b[0m eta: 0:21:59  iter: 679  total_loss: 0.111  loss_cls: 0.028  loss_box_reg: 0.080  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5599  data_time: 0.0072  lr: 0.000170  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:49:27 d2.utils.events]: \u001b[0m eta: 0:21:48  iter: 699  total_loss: 0.115  loss_cls: 0.028  loss_box_reg: 0.084  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 0.5599  data_time: 0.0084  lr: 0.000175  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:49:39 d2.utils.events]: \u001b[0m eta: 0:21:36  iter: 719  total_loss: 0.098  loss_cls: 0.023  loss_box_reg: 0.071  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5598  data_time: 0.0082  lr: 0.000180  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:49:50 d2.utils.events]: \u001b[0m eta: 0:21:25  iter: 739  total_loss: 0.102  loss_cls: 0.029  loss_box_reg: 0.075  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5598  data_time: 0.0081  lr: 0.000185  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:50:01 d2.utils.events]: \u001b[0m eta: 0:21:13  iter: 759  total_loss: 0.102  loss_cls: 0.023  loss_box_reg: 0.071  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 0.5596  data_time: 0.0074  lr: 0.000190  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:50:12 d2.utils.events]: \u001b[0m eta: 0:21:02  iter: 779  total_loss: 0.098  loss_cls: 0.024  loss_box_reg: 0.071  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 0.5595  data_time: 0.0081  lr: 0.000195  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:50:23 d2.utils.events]: \u001b[0m eta: 0:20:51  iter: 799  total_loss: 0.101  loss_cls: 0.022  loss_box_reg: 0.074  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5595  data_time: 0.0079  lr: 0.000200  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:50:34 d2.utils.events]: \u001b[0m eta: 0:20:39  iter: 819  total_loss: 0.095  loss_cls: 0.020  loss_box_reg: 0.078  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5592  data_time: 0.0076  lr: 0.000205  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:50:46 d2.utils.events]: \u001b[0m eta: 0:20:28  iter: 839  total_loss: 0.098  loss_cls: 0.025  loss_box_reg: 0.071  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5594  data_time: 0.0085  lr: 0.000210  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:50:57 d2.utils.events]: \u001b[0m eta: 0:20:17  iter: 859  total_loss: 0.103  loss_cls: 0.026  loss_box_reg: 0.077  loss_rpn_cls: 0.000  loss_rpn_loc: 0.002  time: 0.5591  data_time: 0.0073  lr: 0.000215  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:51:08 d2.utils.events]: \u001b[0m eta: 0:20:05  iter: 879  total_loss: 0.103  loss_cls: 0.022  loss_box_reg: 0.080  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5590  data_time: 0.0074  lr: 0.000220  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:51:19 d2.utils.events]: \u001b[0m eta: 0:19:54  iter: 899  total_loss: 0.099  loss_cls: 0.022  loss_box_reg: 0.071  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5590  data_time: 0.0077  lr: 0.000225  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:51:30 d2.utils.events]: \u001b[0m eta: 0:19:42  iter: 919  total_loss: 0.101  loss_cls: 0.024  loss_box_reg: 0.073  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5590  data_time: 0.0076  lr: 0.000230  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:51:41 d2.utils.events]: \u001b[0m eta: 0:19:31  iter: 939  total_loss: 0.101  loss_cls: 0.024  loss_box_reg: 0.076  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5592  data_time: 0.0076  lr: 0.000235  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:51:53 d2.utils.events]: \u001b[0m eta: 0:19:20  iter: 959  total_loss: 0.103  loss_cls: 0.026  loss_box_reg: 0.081  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5591  data_time: 0.0083  lr: 0.000240  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:52:04 d2.utils.events]: \u001b[0m eta: 0:19:08  iter: 979  total_loss: 0.102  loss_cls: 0.023  loss_box_reg: 0.078  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5590  data_time: 0.0075  lr: 0.000245  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:52:15 d2.utils.events]: \u001b[0m eta: 0:18:57  iter: 999  total_loss: 0.097  loss_cls: 0.022  loss_box_reg: 0.072  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5589  data_time: 0.0074  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:52:26 d2.utils.events]: \u001b[0m eta: 0:18:46  iter: 1019  total_loss: 0.104  loss_cls: 0.025  loss_box_reg: 0.077  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5591  data_time: 0.0082  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:52:37 d2.utils.events]: \u001b[0m eta: 0:18:34  iter: 1039  total_loss: 0.091  loss_cls: 0.025  loss_box_reg: 0.065  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5591  data_time: 0.0074  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:52:48 d2.utils.events]: \u001b[0m eta: 0:18:23  iter: 1059  total_loss: 0.088  loss_cls: 0.019  loss_box_reg: 0.062  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5589  data_time: 0.0081  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:53:00 d2.utils.events]: \u001b[0m eta: 0:18:12  iter: 1079  total_loss: 0.087  loss_cls: 0.017  loss_box_reg: 0.066  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5590  data_time: 0.0085  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:53:11 d2.utils.events]: \u001b[0m eta: 0:18:00  iter: 1099  total_loss: 0.094  loss_cls: 0.025  loss_box_reg: 0.069  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5589  data_time: 0.0079  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:53:22 d2.utils.events]: \u001b[0m eta: 0:17:49  iter: 1119  total_loss: 0.082  loss_cls: 0.022  loss_box_reg: 0.064  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5590  data_time: 0.0074  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:53:33 d2.utils.events]: \u001b[0m eta: 0:17:38  iter: 1139  total_loss: 0.095  loss_cls: 0.024  loss_box_reg: 0.066  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5590  data_time: 0.0080  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:53:44 d2.utils.events]: \u001b[0m eta: 0:17:26  iter: 1159  total_loss: 0.080  loss_cls: 0.021  loss_box_reg: 0.057  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5589  data_time: 0.0078  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:53:56 d2.utils.events]: \u001b[0m eta: 0:17:15  iter: 1179  total_loss: 0.090  loss_cls: 0.023  loss_box_reg: 0.062  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5590  data_time: 0.0082  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:54:07 d2.utils.events]: \u001b[0m eta: 0:17:04  iter: 1199  total_loss: 0.087  loss_cls: 0.019  loss_box_reg: 0.061  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5590  data_time: 0.0085  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:54:18 d2.utils.events]: \u001b[0m eta: 0:16:52  iter: 1219  total_loss: 0.086  loss_cls: 0.021  loss_box_reg: 0.063  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5590  data_time: 0.0074  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:54:29 d2.utils.events]: \u001b[0m eta: 0:16:41  iter: 1239  total_loss: 0.092  loss_cls: 0.019  loss_box_reg: 0.065  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5590  data_time: 0.0073  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:54:41 d2.utils.events]: \u001b[0m eta: 0:16:30  iter: 1259  total_loss: 0.088  loss_cls: 0.021  loss_box_reg: 0.067  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5591  data_time: 0.0077  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:54:52 d2.utils.events]: \u001b[0m eta: 0:16:18  iter: 1279  total_loss: 0.085  loss_cls: 0.019  loss_box_reg: 0.063  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5591  data_time: 0.0086  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:55:03 d2.utils.events]: \u001b[0m eta: 0:16:07  iter: 1299  total_loss: 0.086  loss_cls: 0.024  loss_box_reg: 0.061  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5590  data_time: 0.0082  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:55:14 d2.utils.events]: \u001b[0m eta: 0:15:55  iter: 1319  total_loss: 0.080  loss_cls: 0.019  loss_box_reg: 0.061  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5590  data_time: 0.0085  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:55:25 d2.utils.events]: \u001b[0m eta: 0:15:44  iter: 1339  total_loss: 0.084  loss_cls: 0.022  loss_box_reg: 0.062  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5589  data_time: 0.0082  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:55:36 d2.utils.events]: \u001b[0m eta: 0:15:33  iter: 1359  total_loss: 0.085  loss_cls: 0.022  loss_box_reg: 0.063  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5589  data_time: 0.0082  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:55:48 d2.utils.events]: \u001b[0m eta: 0:15:21  iter: 1379  total_loss: 0.094  loss_cls: 0.021  loss_box_reg: 0.069  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5590  data_time: 0.0077  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:55:59 d2.utils.events]: \u001b[0m eta: 0:15:10  iter: 1399  total_loss: 0.088  loss_cls: 0.020  loss_box_reg: 0.065  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5590  data_time: 0.0078  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:56:10 d2.utils.events]: \u001b[0m eta: 0:14:59  iter: 1419  total_loss: 0.087  loss_cls: 0.022  loss_box_reg: 0.065  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5590  data_time: 0.0080  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:56:21 d2.utils.events]: \u001b[0m eta: 0:14:47  iter: 1439  total_loss: 0.080  loss_cls: 0.019  loss_box_reg: 0.058  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5591  data_time: 0.0072  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:56:33 d2.utils.events]: \u001b[0m eta: 0:14:36  iter: 1459  total_loss: 0.079  loss_cls: 0.018  loss_box_reg: 0.057  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5591  data_time: 0.0077  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:56:44 d2.utils.events]: \u001b[0m eta: 0:14:24  iter: 1479  total_loss: 0.078  loss_cls: 0.021  loss_box_reg: 0.054  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5592  data_time: 0.0078  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:56:55 d2.utils.events]: \u001b[0m eta: 0:14:13  iter: 1499  total_loss: 0.079  loss_cls: 0.020  loss_box_reg: 0.060  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5592  data_time: 0.0085  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:57:06 d2.utils.events]: \u001b[0m eta: 0:14:01  iter: 1519  total_loss: 0.083  loss_cls: 0.021  loss_box_reg: 0.061  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5590  data_time: 0.0076  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:57:17 d2.utils.events]: \u001b[0m eta: 0:13:50  iter: 1539  total_loss: 0.072  loss_cls: 0.017  loss_box_reg: 0.052  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5590  data_time: 0.0079  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:57:28 d2.utils.events]: \u001b[0m eta: 0:13:39  iter: 1559  total_loss: 0.079  loss_cls: 0.018  loss_box_reg: 0.059  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5588  data_time: 0.0080  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:57:39 d2.utils.events]: \u001b[0m eta: 0:13:27  iter: 1579  total_loss: 0.078  loss_cls: 0.019  loss_box_reg: 0.059  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5588  data_time: 0.0089  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:57:51 d2.utils.events]: \u001b[0m eta: 0:13:16  iter: 1599  total_loss: 0.086  loss_cls: 0.021  loss_box_reg: 0.063  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5589  data_time: 0.0078  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:58:02 d2.utils.events]: \u001b[0m eta: 0:13:04  iter: 1619  total_loss: 0.086  loss_cls: 0.020  loss_box_reg: 0.062  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5588  data_time: 0.0080  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:58:13 d2.utils.events]: \u001b[0m eta: 0:12:53  iter: 1639  total_loss: 0.079  loss_cls: 0.021  loss_box_reg: 0.055  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5588  data_time: 0.0076  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:58:24 d2.utils.events]: \u001b[0m eta: 0:12:42  iter: 1659  total_loss: 0.084  loss_cls: 0.021  loss_box_reg: 0.059  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5588  data_time: 0.0078  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:58:35 d2.utils.events]: \u001b[0m eta: 0:12:30  iter: 1679  total_loss: 0.076  loss_cls: 0.019  loss_box_reg: 0.057  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5589  data_time: 0.0077  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:58:47 d2.utils.events]: \u001b[0m eta: 0:12:19  iter: 1699  total_loss: 0.089  loss_cls: 0.022  loss_box_reg: 0.065  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5589  data_time: 0.0079  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:58:58 d2.utils.events]: \u001b[0m eta: 0:12:08  iter: 1719  total_loss: 0.076  loss_cls: 0.018  loss_box_reg: 0.057  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5589  data_time: 0.0076  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:59:09 d2.utils.events]: \u001b[0m eta: 0:11:56  iter: 1739  total_loss: 0.085  loss_cls: 0.021  loss_box_reg: 0.059  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5589  data_time: 0.0081  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:59:20 d2.utils.events]: \u001b[0m eta: 0:11:45  iter: 1759  total_loss: 0.076  loss_cls: 0.016  loss_box_reg: 0.054  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5588  data_time: 0.0091  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:59:31 d2.utils.events]: \u001b[0m eta: 0:11:34  iter: 1779  total_loss: 0.080  loss_cls: 0.019  loss_box_reg: 0.062  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5588  data_time: 0.0083  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:59:43 d2.utils.events]: \u001b[0m eta: 0:11:22  iter: 1799  total_loss: 0.079  loss_cls: 0.018  loss_box_reg: 0.061  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5588  data_time: 0.0077  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 02:59:54 d2.utils.events]: \u001b[0m eta: 0:11:11  iter: 1819  total_loss: 0.087  loss_cls: 0.018  loss_box_reg: 0.063  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5587  data_time: 0.0085  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:00:05 d2.utils.events]: \u001b[0m eta: 0:10:59  iter: 1839  total_loss: 0.072  loss_cls: 0.017  loss_box_reg: 0.055  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5587  data_time: 0.0076  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:00:16 d2.utils.events]: \u001b[0m eta: 0:10:48  iter: 1859  total_loss: 0.076  loss_cls: 0.019  loss_box_reg: 0.054  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5588  data_time: 0.0076  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:00:27 d2.utils.events]: \u001b[0m eta: 0:10:37  iter: 1879  total_loss: 0.081  loss_cls: 0.018  loss_box_reg: 0.062  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5588  data_time: 0.0084  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:00:38 d2.utils.events]: \u001b[0m eta: 0:10:25  iter: 1899  total_loss: 0.073  loss_cls: 0.016  loss_box_reg: 0.057  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5588  data_time: 0.0078  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:00:49 d2.utils.events]: \u001b[0m eta: 0:10:14  iter: 1919  total_loss: 0.082  loss_cls: 0.018  loss_box_reg: 0.061  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5587  data_time: 0.0077  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:01:01 d2.utils.events]: \u001b[0m eta: 0:10:02  iter: 1939  total_loss: 0.076  loss_cls: 0.019  loss_box_reg: 0.057  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5588  data_time: 0.0078  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:01:12 d2.utils.events]: \u001b[0m eta: 0:09:51  iter: 1959  total_loss: 0.075  loss_cls: 0.018  loss_box_reg: 0.057  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5587  data_time: 0.0084  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:01:23 d2.utils.events]: \u001b[0m eta: 0:09:40  iter: 1979  total_loss: 0.084  loss_cls: 0.020  loss_box_reg: 0.063  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5588  data_time: 0.0088  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:01:34 d2.utils.events]: \u001b[0m eta: 0:09:28  iter: 1999  total_loss: 0.071  loss_cls: 0.016  loss_box_reg: 0.053  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5588  data_time: 0.0079  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:01:46 d2.utils.events]: \u001b[0m eta: 0:09:17  iter: 2019  total_loss: 0.079  loss_cls: 0.019  loss_box_reg: 0.056  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5588  data_time: 0.0074  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:01:57 d2.utils.events]: \u001b[0m eta: 0:09:06  iter: 2039  total_loss: 0.077  loss_cls: 0.017  loss_box_reg: 0.057  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5589  data_time: 0.0073  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:02:08 d2.utils.events]: \u001b[0m eta: 0:08:54  iter: 2059  total_loss: 0.079  loss_cls: 0.015  loss_box_reg: 0.060  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5589  data_time: 0.0086  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:02:19 d2.utils.events]: \u001b[0m eta: 0:08:43  iter: 2079  total_loss: 0.072  loss_cls: 0.018  loss_box_reg: 0.057  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5589  data_time: 0.0077  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:02:31 d2.utils.events]: \u001b[0m eta: 0:08:32  iter: 2099  total_loss: 0.074  loss_cls: 0.018  loss_box_reg: 0.055  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5589  data_time: 0.0078  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:02:42 d2.utils.events]: \u001b[0m eta: 0:08:20  iter: 2119  total_loss: 0.080  loss_cls: 0.020  loss_box_reg: 0.060  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5589  data_time: 0.0075  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:02:53 d2.utils.events]: \u001b[0m eta: 0:08:09  iter: 2139  total_loss: 0.076  loss_cls: 0.020  loss_box_reg: 0.058  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5589  data_time: 0.0079  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:03:04 d2.utils.events]: \u001b[0m eta: 0:07:58  iter: 2159  total_loss: 0.082  loss_cls: 0.021  loss_box_reg: 0.058  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5588  data_time: 0.0080  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:03:15 d2.utils.events]: \u001b[0m eta: 0:07:46  iter: 2179  total_loss: 0.073  loss_cls: 0.017  loss_box_reg: 0.054  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5588  data_time: 0.0085  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:03:26 d2.utils.events]: \u001b[0m eta: 0:07:35  iter: 2199  total_loss: 0.068  loss_cls: 0.015  loss_box_reg: 0.051  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5588  data_time: 0.0083  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:03:37 d2.utils.events]: \u001b[0m eta: 0:07:23  iter: 2219  total_loss: 0.075  loss_cls: 0.018  loss_box_reg: 0.053  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5588  data_time: 0.0074  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:03:49 d2.utils.events]: \u001b[0m eta: 0:07:12  iter: 2239  total_loss: 0.070  loss_cls: 0.016  loss_box_reg: 0.052  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5588  data_time: 0.0084  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:04:00 d2.utils.events]: \u001b[0m eta: 0:07:01  iter: 2259  total_loss: 0.070  loss_cls: 0.016  loss_box_reg: 0.053  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5589  data_time: 0.0082  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:04:11 d2.utils.events]: \u001b[0m eta: 0:06:49  iter: 2279  total_loss: 0.069  loss_cls: 0.017  loss_box_reg: 0.049  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5589  data_time: 0.0080  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:04:22 d2.utils.events]: \u001b[0m eta: 0:06:38  iter: 2299  total_loss: 0.072  loss_cls: 0.016  loss_box_reg: 0.056  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5589  data_time: 0.0079  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:04:34 d2.utils.events]: \u001b[0m eta: 0:06:27  iter: 2319  total_loss: 0.080  loss_cls: 0.018  loss_box_reg: 0.059  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5588  data_time: 0.0082  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:04:45 d2.utils.events]: \u001b[0m eta: 0:06:15  iter: 2339  total_loss: 0.073  loss_cls: 0.018  loss_box_reg: 0.052  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5589  data_time: 0.0083  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:04:56 d2.utils.events]: \u001b[0m eta: 0:06:04  iter: 2359  total_loss: 0.065  loss_cls: 0.016  loss_box_reg: 0.051  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5589  data_time: 0.0079  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:05:07 d2.utils.events]: \u001b[0m eta: 0:05:52  iter: 2379  total_loss: 0.076  loss_cls: 0.019  loss_box_reg: 0.057  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5589  data_time: 0.0078  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:05:18 d2.utils.events]: \u001b[0m eta: 0:05:41  iter: 2399  total_loss: 0.066  loss_cls: 0.014  loss_box_reg: 0.050  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5589  data_time: 0.0086  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:05:30 d2.utils.events]: \u001b[0m eta: 0:05:30  iter: 2419  total_loss: 0.075  loss_cls: 0.015  loss_box_reg: 0.056  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5589  data_time: 0.0082  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:05:41 d2.utils.events]: \u001b[0m eta: 0:05:18  iter: 2439  total_loss: 0.076  loss_cls: 0.016  loss_box_reg: 0.053  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5589  data_time: 0.0074  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:05:52 d2.utils.events]: \u001b[0m eta: 0:05:07  iter: 2459  total_loss: 0.076  loss_cls: 0.016  loss_box_reg: 0.055  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5589  data_time: 0.0076  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:06:03 d2.utils.events]: \u001b[0m eta: 0:04:56  iter: 2479  total_loss: 0.076  loss_cls: 0.017  loss_box_reg: 0.055  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5589  data_time: 0.0075  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:06:15 d2.utils.events]: \u001b[0m eta: 0:04:44  iter: 2499  total_loss: 0.066  loss_cls: 0.016  loss_box_reg: 0.052  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5589  data_time: 0.0080  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:06:26 d2.utils.events]: \u001b[0m eta: 0:04:33  iter: 2519  total_loss: 0.070  loss_cls: 0.018  loss_box_reg: 0.050  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5589  data_time: 0.0077  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:06:37 d2.utils.events]: \u001b[0m eta: 0:04:22  iter: 2539  total_loss: 0.076  loss_cls: 0.017  loss_box_reg: 0.056  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5589  data_time: 0.0084  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:06:48 d2.utils.events]: \u001b[0m eta: 0:04:10  iter: 2559  total_loss: 0.066  loss_cls: 0.015  loss_box_reg: 0.049  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5589  data_time: 0.0082  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:06:59 d2.utils.events]: \u001b[0m eta: 0:03:59  iter: 2579  total_loss: 0.072  loss_cls: 0.016  loss_box_reg: 0.057  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5590  data_time: 0.0083  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:07:11 d2.utils.events]: \u001b[0m eta: 0:03:48  iter: 2599  total_loss: 0.062  loss_cls: 0.017  loss_box_reg: 0.045  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5590  data_time: 0.0076  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:07:22 d2.utils.events]: \u001b[0m eta: 0:03:36  iter: 2619  total_loss: 0.063  loss_cls: 0.014  loss_box_reg: 0.046  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5589  data_time: 0.0084  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:07:33 d2.utils.events]: \u001b[0m eta: 0:03:25  iter: 2639  total_loss: 0.067  loss_cls: 0.014  loss_box_reg: 0.049  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5589  data_time: 0.0088  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:07:44 d2.utils.events]: \u001b[0m eta: 0:03:13  iter: 2659  total_loss: 0.074  loss_cls: 0.016  loss_box_reg: 0.056  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5590  data_time: 0.0074  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:07:55 d2.utils.events]: \u001b[0m eta: 0:03:02  iter: 2679  total_loss: 0.072  loss_cls: 0.015  loss_box_reg: 0.055  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5590  data_time: 0.0072  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:08:07 d2.utils.events]: \u001b[0m eta: 0:02:51  iter: 2699  total_loss: 0.072  loss_cls: 0.014  loss_box_reg: 0.053  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5590  data_time: 0.0076  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:08:18 d2.utils.events]: \u001b[0m eta: 0:02:39  iter: 2719  total_loss: 0.064  loss_cls: 0.015  loss_box_reg: 0.048  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5590  data_time: 0.0079  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:08:29 d2.utils.events]: \u001b[0m eta: 0:02:28  iter: 2739  total_loss: 0.076  loss_cls: 0.015  loss_box_reg: 0.059  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5590  data_time: 0.0081  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:08:40 d2.utils.events]: \u001b[0m eta: 0:02:17  iter: 2759  total_loss: 0.073  loss_cls: 0.015  loss_box_reg: 0.055  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5590  data_time: 0.0086  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:08:52 d2.utils.events]: \u001b[0m eta: 0:02:05  iter: 2779  total_loss: 0.064  loss_cls: 0.013  loss_box_reg: 0.048  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5590  data_time: 0.0074  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:09:03 d2.utils.events]: \u001b[0m eta: 0:01:54  iter: 2799  total_loss: 0.070  loss_cls: 0.015  loss_box_reg: 0.052  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5590  data_time: 0.0078  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:09:14 d2.utils.events]: \u001b[0m eta: 0:01:42  iter: 2819  total_loss: 0.065  loss_cls: 0.014  loss_box_reg: 0.048  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5590  data_time: 0.0081  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:09:25 d2.utils.events]: \u001b[0m eta: 0:01:31  iter: 2839  total_loss: 0.069  loss_cls: 0.014  loss_box_reg: 0.053  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5590  data_time: 0.0075  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:09:36 d2.utils.events]: \u001b[0m eta: 0:01:20  iter: 2859  total_loss: 0.069  loss_cls: 0.016  loss_box_reg: 0.055  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5590  data_time: 0.0079  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:09:48 d2.utils.events]: \u001b[0m eta: 0:01:08  iter: 2879  total_loss: 0.071  loss_cls: 0.017  loss_box_reg: 0.053  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5591  data_time: 0.0075  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:09:59 d2.utils.events]: \u001b[0m eta: 0:00:57  iter: 2899  total_loss: 0.070  loss_cls: 0.015  loss_box_reg: 0.054  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5591  data_time: 0.0081  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:10:10 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 2919  total_loss: 0.074  loss_cls: 0.014  loss_box_reg: 0.061  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5591  data_time: 0.0088  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:10:21 d2.utils.events]: \u001b[0m eta: 0:00:34  iter: 2939  total_loss: 0.070  loss_cls: 0.017  loss_box_reg: 0.050  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5591  data_time: 0.0075  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:10:33 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 2959  total_loss: 0.074  loss_cls: 0.016  loss_box_reg: 0.057  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5591  data_time: 0.0081  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:10:44 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 2979  total_loss: 0.066  loss_cls: 0.014  loss_box_reg: 0.050  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5591  data_time: 0.0076  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:10:56 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|  BAO CAM   | 212          |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[09/04 03:10:56 d2.data.common]: \u001b[0mSerializing 210 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/04 03:10:56 d2.data.common]: \u001b[0mSerialized dataset takes 0.05 MiB\n",
      "\u001b[32m[09/04 03:10:56 d2.data.dataset_mapper]: \u001b[0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[09/04 03:10:56 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "\u001b[32m[09/04 03:10:56 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 2999  total_loss: 0.069  loss_cls: 0.014  loss_box_reg: 0.054  loss_rpn_cls: 0.000  loss_rpn_loc: 0.001  time: 0.5591  data_time: 0.0074  lr: 0.000250  max_mem: 7797M\n",
      "\u001b[32m[09/04 03:10:56 d2.engine.hooks]: \u001b[0mOverall training speed: 2997 iterations in 0:27:56 (0.5593 s / it)\n",
      "\u001b[32m[09/04 03:10:56 d2.engine.hooks]: \u001b[0mTotal training time: 0:27:59 (0:00:03 on hooks)\n"
     ]
    }
   ],
   "source": [
    "train(dataset, 'baocam', classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
