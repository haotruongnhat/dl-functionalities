{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Bao cam - 800 0.95 R101_FPN_3x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer import *\n",
    "import notebook_utils as nutils\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sort import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "classes = ['BAO CAM']\n",
    "# predictor = get_predictor(\"baocam_faster_rcnn_R_101_FPN_3x.yaml.pth\", classes, 800 , 0.5)\n",
    "predictor = get_predictor(\"baocam_faster_rcnn_R_101_FPN_3x.yaml.pth\", classes, 800 , 0.95)\n",
    "\n",
    "file = 'BAOCAM/6/7.JPG'\n",
    "bboxes, classes, scores, v = infer('baocam', predictor, file, True, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nutils.gdrive_down(\"1f6-Focz7eiRxia38H8nSxvghd5eAJxne\", \"CPL_FGAGro_38_63-20200917-070419.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp4_files = nutils.list_files(\"data\", \"CAM 1-*.mp4\")\n",
    "path = mp4_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp4_files = [Path(\"CPL_FGAGro_38_63-20200917-070419.mp4\")]\n",
    "path = mp4_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for path in mp4_files:\n",
    "    out = cv2.VideoWriter(\"temp.mp4\",cv2.VideoWriter_fourcc(*'MP4V'), 15, (640, 360)) #(640, 360) (285, 360)\n",
    "    \n",
    "    vc = cv2.VideoCapture(str(path))\n",
    "    time_per_frame = (1/vc.get(cv2.CAP_PROP_FPS)) * 1000\n",
    "    #start_frame = 10800#12600 #10800\n",
    "    vc.set(1,0);\n",
    "\n",
    "    rval = True\n",
    "\n",
    "    frame_id = 0\n",
    "    max_frame = int(vc.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "#     max_frame = 300\n",
    "\n",
    "    counter = 0\n",
    "\n",
    "    pbar = tqdm(total=max_frame, position=0, leave=True)\n",
    "    \n",
    "    mot_tracker = Sort(max_age=0, min_hits= 0, iou_threshold=0.1)\n",
    "    mot_tracker.reset_count()\n",
    "    while rval:\n",
    "        rval , frame = vc.read()\n",
    "\n",
    "        if rval:\n",
    "            start = time.time()\n",
    "\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#             image = image[..., 350:920, :].copy()\n",
    "            \n",
    "            bboxes, classes, scores, v = infer('baocam', predictor, image, True, 0.5)\n",
    "#             print(scores)\n",
    "#             ret, bboxes = process_stick_two_object(bboxes, 550)\n",
    "            bboxes_with_scores = np.hstack((bboxes, scores.reshape(bboxes.shape[0],1)))\n",
    "#             print(bboxes_with_scores)\n",
    "            track_bbs_ids = mot_tracker.update(bboxes_with_scores)\n",
    "\n",
    "            total_time = (time.time() - start) * 1000\n",
    "\n",
    "#             v.draw_text(\"\\n\".join([\"-\".join(bbox + [str(round(scores[index], 3))]) for index, bbox in enumerate(bboxes.astype(np.int32).astype(np.str).tolist())]), \n",
    "#                         (200, 100), font_size= 30, color='g')\n",
    "\n",
    "\n",
    "            for bbox in bboxes:\n",
    "                v.draw_box(bbox, alpha = 1)\n",
    "\n",
    "            for bbox in track_bbs_ids:\n",
    "                counter = bbox[-1]\n",
    "                v.draw_text(str(int(counter)), (int( (bbox[0] + bbox[2]) /2 ) , int((bbox[1] + bbox[3]) /2 )), font_size= 70, color='g')\n",
    "\n",
    "\n",
    "            v.draw_text(str(int(counter)) + (\"*\" if False else \"\"), (100 , 100), font_size= 70, color='g')\n",
    "\n",
    "            predicted_image = v.output.get_image()\n",
    "\n",
    "            skip_frame = int(np.ceil(total_time / time_per_frame))\n",
    "#             print(skip_frame)\n",
    "#             skip_frame = 3\n",
    "#             print(skip_frame)\n",
    "            out.write(predicted_image)\n",
    "\n",
    "            frame_id += 1\n",
    "            pbar.update(1)\n",
    "            \n",
    "            for i in range(skip_frame+1):\n",
    "                out.write(predicted_image)\n",
    "                vc.read()\n",
    "                pbar.update(1)\n",
    "                frame_id += 1\n",
    "\n",
    "            if frame_id > (max_frame - 0):\n",
    "                break\n",
    "\n",
    "    out.release()\n",
    "    vc.release()\n",
    "\n",
    "    new_file = \"{}_export.mp4\".format(path.stem).replace(\" \", \"\") \n",
    "    cmd = \"ffmpeg -i temp.mp4 -vcodec libx264 {} -y\".format(new_file)\n",
    "    print(cmd)\n",
    "    os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "Video(new_file, width = 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.release()\n",
    "vc.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.draw_box(bboxes[0])\n",
    "\n",
    "out = v.output.get_image()\n",
    "\n",
    "nutils.imshow(out, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = cv2.VideoCapture(str(path))\n",
    "\n",
    "start_frame = 12640\n",
    "vc.set(1,start_frame);\n",
    "\n",
    "mot_tracker = Sort(min_hits= 0) \n",
    "mot_tracker.reset_count()\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_stick_two_object(bboxes, thresh):\n",
    "    a = bboxes.copy()\n",
    "    \n",
    "    max_height_to_split = thresh\n",
    "\n",
    "    long_indices = np.where(a[:, 3] - a[:, 1] > max_height_to_split)[0]\n",
    "\n",
    "    split_bboxes = []\n",
    "    ret = False\n",
    "    if len(long_indices) >0:\n",
    "        print('There stick bboxes')\n",
    "        ret = True\n",
    "        for i in range(len(a)):\n",
    "            if len(np.where(long_indices == i)[0]) > 0:\n",
    "                bbox = a[i]\n",
    "                center_height = bbox[3] - bbox[1]\n",
    "                center_height *= 0.7\n",
    "\n",
    "                split_bboxes.append([bbox[0], bbox[1], bbox[2], center_height])\n",
    "                split_bboxes.append([bbox[0], center_height, bbox[2], bbox[3]])\n",
    "            else:\n",
    "                split_bboxes.append(a[i])\n",
    "        \n",
    "        a = np.array(split_bboxes)\n",
    "    \n",
    "    return ret, a\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = cv2.VideoCapture(str(path))\n",
    "vc.set(1, 4000);\n",
    "mot_tracker = Sort(max_age = 0, min_hits= 0)\n",
    "mot_tracker.reset_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "time_per_frame = (1/30) * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['BAO CAM']\n",
    "predictor = get_predictor(\"baocam.pth\", classes, 400 , 0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rval , frame = vc.read()\n",
    "start = time.time()\n",
    "\n",
    "image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "# image = image[..., 350:920, :].copy()\n",
    "\n",
    "bboxes, classes, scores, v = infer('baocam', predictor, image, True, 0.5)\n",
    "\n",
    "print(bboxes, scores)\n",
    "# ret, bboxes = process_stick_two_object(bboxes, 530)\n",
    "# print(bboxes)\n",
    "\n",
    "track_bbs_ids = mot_tracker.update(bboxes)\n",
    "\n",
    "\n",
    "for bbox in bboxes:\n",
    "    v.draw_box(bbox, 1)\n",
    "    \n",
    "    \n",
    "for bbox in track_bbs_ids:\n",
    "    v.draw_box(bbox[:4], edge_color='r')\n",
    "    v.draw_text(str(int(bbox[-1])), (int( (bbox[0] + bbox[2]) /2 ) , int((bbox[1] + bbox[3]) /2 )), font_size= 40, color='g')\n",
    "\n",
    "try:\n",
    "    counter = max(track_bbs_ids[..., -1])\n",
    "except:\n",
    "    pass\n",
    "v.draw_text(str(int(counter)), (50 , 100), font_size= 50, color='g')\n",
    "\n",
    "predicted_image = v.output.get_image()\n",
    "\n",
    "total_time = (time.time() - start) * 1000\n",
    "\n",
    "skip_frame = int(np.ceil(total_time / time_per_frame))\n",
    "\n",
    "\n",
    "for i in range(skip_frame):\n",
    "    vc.read()\n",
    "    \n",
    "nutils.imshow(predicted_image, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_stick_two_object(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[475.5481 , 107.80378, 801.6652 , 705.3319 ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_height_to_split = 500\n",
    "\n",
    "long_indices = np.where(a[:, 3] - a[:, 1] > max_height_to_split)[0]\n",
    "\n",
    "split_bboxes = []\n",
    "\n",
    "if len(long_indices) >0:\n",
    "    for i in range(len(a)):\n",
    "        if len(np.where(long_indices == i)[0]) > 0:\n",
    "            bbox = a[i]\n",
    "            center_height = bbox[3] - bbox[1]\n",
    "            center_height *= 0.7\n",
    "            \n",
    "            split_bboxes.append([bbox[0], bbox[1], bbox[2], center_height])\n",
    "            split_bboxes.append([bbox[0], center_height, bbox[2], bbox[3]])\n",
    "        else:\n",
    "            split_bboxes.append(a[i])\n",
    "        print(i)\n",
    "        print(split_bboxes)\n",
    "            \n",
    "        \n",
    "a = np.array(split_bboxes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
